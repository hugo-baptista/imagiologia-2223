{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ficha MLP Binary\n",
    "PG50416 Hugo Baptista Fernandes Silva\n",
    "### 0. Instalação PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "# Confirmar a instalação\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for binary classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import BCELoss, BCEWithLogitsLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "#path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "PATH = 'ionosphere.csv'\n",
    "device = torch.device(\"cpu\")\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([235, 34]) torch.Size([235, 1])\n",
      "torch.Size([116, 34]) torch.Size([116, 1])\n"
     ]
    }
   ],
   "source": [
    "# definição classe para o dataset\n",
    "class CSVDataset(Dataset):\n",
    "    # ler o dataset\n",
    "    def __init__(self, path):\n",
    "        # ler o ficheiro csv para um dataframe\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        # separar os inputs e os outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        # garantir que os inputs sejam floats\n",
    "        self.X = self.X.astype('float32')\n",
    "        # fazer o encoding dos outputs (label) e garantir que sejam floats\n",
    "        self.y = LabelEncoder().fit_transform(self.y) #faz o fit e transforma no self.y o 'g' e o 'b' em 0 e 1\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))   \n",
    "            \n",
    "    # número de casos no dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    # retornar um caso\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "    \n",
    "    # retornar índices para casos de treino e de teste\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # calcular o tamanho para o split\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calcular o split do houldout\n",
    "        return random_split(self, [train_size, test_size])#, generator=torch.Generator().manual_seed(42)) \n",
    "    \n",
    "# preparar o dataset\n",
    "def prepare_data(path):\n",
    "    # criar uma instância do dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calcular o split\n",
    "    train, test = dataset.get_splits()\n",
    "    # preparar os data loaders\n",
    "    train_dl = DataLoader(train, batch_size=len(train), shuffle=True) # batch_size=BATCH_SIZE e shuffle=False\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=False)\n",
    "    test_dl_all = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "    return train_dl, test_dl, train_dl_all, test_dl_all\n",
    "\n",
    "# preparar os dados\n",
    "train_dl, test_dl, train_dl_all, test_dl_all = prepare_data(PATH)\n",
    "\n",
    "# sanity check\n",
    "x,y = next(iter(train_dl))\n",
    "print(x.shape, y.shape)\n",
    "x,y = next(iter(test_dl))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (hidden1): Linear(in_features=34, out_features=10, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=10, out_features=8, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act3): Sigmoid()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Definição da classe para o modelo\n",
    "class MLP(Module):\n",
    "    # definir elementos do modelo\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input para a primeira camada - Linear - ReLU\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')# He initialization\n",
    "        self.act1 = ReLU()\n",
    "        # segunda camada - Linear - ReLU\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # terceira camada e output Linear - Sigmoid\n",
    "        self.hidden3 = Linear(8, 1)\n",
    "        xavier_uniform_(self.hidden3.weight) # Glorot initialization\n",
    "        self.act3 = Sigmoid()\n",
    "\n",
    "    # sequência de propagação do input\n",
    "    def forward(self, X):\n",
    "        # input para a primeira camada\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # input para a segunda camada\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # input para a terceira camada e output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n",
    "\n",
    "# definir a rede neuronal\n",
    "model = MLP(34) #34 entradas\n",
    "print(model.parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino do modelo\n",
    "def train_model(train_dl, model):\n",
    "    # definir a função de loss e a função de otimização\n",
    "    criterion = BCELoss() # Binary Cross Entropy - precisa de sigmoid como função de ativação na saída\n",
    "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9) # stochastic gradient descent\n",
    "    # iterar as epochs\n",
    "    for epoch in range(EPOCHS):\n",
    "        # iterar as batchs\n",
    "        for i, (inputs, targets) in enumerate(train_dl):# backpropagation\n",
    "            # inicializar os gradientes\n",
    "            optimizer.zero_grad() # coloca os gradientes de todos os parametros a zero\n",
    "            # calcular o output do modelo - previsao/forward\n",
    "            yprev = model(inputs)\n",
    "            # calcular o loss\n",
    "            loss = criterion(yprev, targets)\n",
    "            # atribuição alteraçoes \"In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "            # with respect to the output, and we need to compute the gradient of the loss with respect to the input.\n",
    "            loss.backward() # backpropagation\n",
    "            # update pesos do modelo\n",
    "            optimizer.step()\n",
    "\n",
    "# treinar o modelo\n",
    "train_model(train_dl, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.690\n",
      "\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[0.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[0.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[0.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[0.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[0.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[0.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[0.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[0.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[1.] previsão:[1.]\n",
      "real:[0.] previsão:[1.]\n",
      "acertou:80 falhou:36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.18      0.31        44\n",
      "         1.0       0.67      1.00      0.80        72\n",
      "\n",
      "    accuracy                           0.69       116\n",
      "   macro avg       0.83      0.59      0.55       116\n",
      "weighted avg       0.79      0.69      0.61       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions = list()\n",
    "    actual_values = list()\n",
    "    for i, (inputs, labels) in enumerate(test_dl):\n",
    "        # avaliar o modelo com os casos de teste\n",
    "        yprev = model(inputs)\n",
    "        # retirar o array numpy\n",
    "        yprev = yprev.detach().numpy()\n",
    "        actual = labels.numpy()\n",
    "        # arredondar para obter a classe\n",
    "        yprev = yprev.round()\n",
    "        # guardar\n",
    "        predictions.append(yprev)\n",
    "        actual_values.append(actual)\n",
    "    predictions, actual_values = np.vstack(predictions), np.vstack(actual_values)\n",
    "    return predictions, actual_values\n",
    "\n",
    "# avaliar o modelo\n",
    "predictions, actual_values = evaluate_model(test_dl, model)\n",
    "# calcular a accuracy\n",
    "acc = accuracy_score(actual_values, predictions)\n",
    "print(f'Accuracy: {acc:0.3f}\\n')\n",
    "\n",
    "acertou=0\n",
    "falhou = 0\n",
    "for r,p in zip(actual_values, predictions):\n",
    "    print(f'real:{r} previsão:{p}')\n",
    "    if r==p: acertou+=1\n",
    "    else: falhou+=1\n",
    "print(f'acertou:{acertou} falhou:{falhou}')\n",
    "\n",
    "# relatório de classificação: precision, recall, f1-score, support vs. 0,1, accuracy, macro avg, weighted avg\n",
    "print(classification_report(actual_values, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Usar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.721 (class=1)\n"
     ]
    }
   ],
   "source": [
    "# fazer uma previsão utilizando um caso\n",
    "def predict(row, model):\n",
    "    # converter row para tensor\n",
    "    row = Tensor([row])\n",
    "    # fazer a previsão\n",
    "    yprev = model(row)\n",
    "    # retirar o array numpy\n",
    "    yprev = yprev.detach().numpy()\n",
    "    return yprev\n",
    "\n",
    "# fazer uma única previsão (classe esperada = 1)\n",
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yprev = predict(row, model)\n",
    "print('Predicted: %.3f (class=%d)' % (yprev, yprev.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
